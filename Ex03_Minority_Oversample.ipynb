{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from imblearn.datasets import fetch_datasets\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import *\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = fetch_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS_13 = [\n",
    "    'ecoli',\n",
    "    'satimage',\n",
    "    'abalone',\n",
    "    'us_crime',\n",
    "    'yeast_ml8',\n",
    "    'scene',\n",
    "    'coil_2000',\n",
    "    'solar_flare_m0',\n",
    "    'oil',\n",
    "    'wine_quality',\n",
    "    'yeast_me2',\n",
    "    'ozone_level',\n",
    "    'abalone_19'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_train_X_y(X_train, y_train):\n",
    "    minority_data = X_train[y_train==1]\n",
    "    majority_data = X_train[y_train==0]\n",
    "\n",
    "    oversampled_minority_data = minority_data[np.random.choice(minority_data.shape[0], len(majority_data), replace=True)]\n",
    "    \n",
    "    X_res = np.concatenate((oversampled_minority_data, majority_data))    \n",
    "    y_res = np.concatenate((np.ones(len(oversampled_minority_data)), np.zeros(len(majority_data))))\n",
    "    \n",
    "    return X_res, y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(X, y, random_state, n_folds=5):\n",
    "    pred_probas = np.zeros(len(X))\n",
    "    \n",
    "    folds = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=random_state)\n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(X, y)):\n",
    "        X_train = X[train_idx]\n",
    "        X_valid = X[valid_idx]\n",
    "\n",
    "        y_train = y[train_idx]\n",
    "        y_valid = y[valid_idx]\n",
    "        \n",
    "        X_res, y_res = resample_train_X_y(X_train, y_train)\n",
    "\n",
    "        model = RandomForestClassifier(random_state=random_state)    \n",
    "        model = model.fit(X_res, y_res)\n",
    "\n",
    "        valid_pred_proba = model.predict_proba(X_valid)[:,1]    \n",
    "        pred_probas[valid_idx] += valid_pred_proba\n",
    "        \n",
    "    return pred_probas    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_gmeans(y, pred_probas):\n",
    "    fpr, tpr, thresholds = roc_curve(y, pred_probas)\n",
    "    gmeans = np.sqrt(tpr * (1-fpr))\n",
    "    ix = np.argmax(gmeans)\n",
    "    return gmeans[ix]\n",
    "\n",
    "def calc_f1(y, pred_probas):\n",
    "    precision, recall, thresholds = precision_recall_curve(y, pred_probas)\n",
    "    fscore = []\n",
    "    for p, r in zip(precision, recall):\n",
    "        f1 = (2 * p * r) / (p + r)\n",
    "        if 0.0 <= f1 <= 1.0:\n",
    "            fscore.append(f1)    \n",
    "    ix = np.argmax(fscore)\n",
    "    return fscore[ix]\n",
    "\n",
    "def train_and_evaluate(dataset_name, num_runs=10):\n",
    "    gmeans_scores, f1_scores = [], []\n",
    "    \n",
    "    dataset = datasets[dataset_name]\n",
    "    X = dataset.data\n",
    "    y = np.where(dataset.target == -1, 0, 1) \n",
    "    \n",
    "    for run in range(num_runs):\n",
    "        pred_probas = run_model(X, y, random_state=run)\n",
    "        gmeans_scores.append(calc_gmeans(y, pred_probas))\n",
    "        f1_scores.append(calc_f1(y, pred_probas))\n",
    "        \n",
    "    return gmeans_scores, f1_scores    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set #1: ecoli\n",
      "Set #2: satimage\n",
      "Set #3: abalone\n",
      "Set #4: us_crime\n",
      "Set #5: yeast_ml8\n",
      "Set #6: scene\n",
      "Set #7: coil_2000\n",
      "Set #8: solar_flare_m0\n",
      "Set #9: oil\n",
      "Set #10: wine_quality\n",
      "Set #11: yeast_me2\n",
      "Set #12: ozone_level\n",
      "Set #13: abalone_19\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for i, dataset_name in enumerate(DATASETS_13):\n",
    "    print(\"Set #%d: %s\" % ((i+1), dataset_name))\n",
    "    gmeans_scores, f1_scores = train_and_evaluate(dataset_name)\n",
    "    results[dataset_name] = (np.mean(gmeans_scores), np.std(gmeans_scores), np.mean(f1_scores), np.std(f1_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset\t\tGMeans (mean)\tGMeans(std)\tF1 (mean)\tF1(std)\n",
      "ecoli          \t0.8818\t\t0.0090\t\t0.6212\t\t0.0255\n",
      "satimage       \t0.8987\t\t0.0028\t\t0.6920\t\t0.0035\n",
      "abalone        \t0.7816\t\t0.0063\t\t0.4013\t\t0.0090\n",
      "us_crime       \t0.8533\t\t0.0057\t\t0.5249\t\t0.0105\n",
      "yeast_ml8      \t0.5764\t\t0.0119\t\t0.1705\t\t0.0070\n",
      "scene          \t0.7350\t\t0.0081\t\t0.3178\t\t0.0133\n",
      "coil_2000      \t0.6591\t\t0.0046\t\t0.2139\t\t0.0031\n",
      "solar_flare_m0 \t0.7118\t\t0.0192\t\t0.2111\t\t0.0215\n",
      "oil            \t0.8728\t\t0.0126\t\t0.6037\t\t0.0247\n",
      "wine_quality   \t0.8108\t\t0.0069\t\t0.4264\t\t0.0184\n",
      "yeast_me2      \t0.8531\t\t0.0120\t\t0.4592\t\t0.0342\n",
      "ozone_level    \t0.8153\t\t0.0110\t\t0.3696\t\t0.0109\n",
      "abalone_19     \t0.6666\t\t0.0330\t\t0.0894\t\t0.0198\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset\\t\\tGMeans (mean)\\tGMeans(std)\\tF1 (mean)\\tF1(std)\")\n",
    "for dataset, r in results.items():\n",
    "    print(\"%-15s\\t%.4f\\t\\t%.4f\\t\\t%.4f\\t\\t%.4f\" % (dataset, *(r)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results\\ex03_minority_oversample.pk\", \"wb\") as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
